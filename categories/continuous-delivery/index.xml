<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Continuous Delivery on Coders Digest</title>
    <link>http://abhipandey.com/categories/continuous-delivery/</link>
    <description>Recent content in Continuous Delivery on Coders Digest</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Jul 2016 23:26:44 +0800</lastBuildDate>
    
	<atom:link href="http://abhipandey.com/categories/continuous-delivery/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Systemd tutorial</title>
      <link>http://abhipandey.com/2016/07/systemd-tutorial/</link>
      <pubDate>Thu, 07 Jul 2016 23:26:44 +0800</pubDate>
      
      <guid>http://abhipandey.com/2016/07/systemd-tutorial/</guid>
      <description>Systemd usually requires two files:
 service file timer file  Service files Here you provide the details you&amp;rsquo;d use to
 Start/stop a service Define the type of service  Can be simple, forking, oneshot, dbus, notify or idle  How to kill the service Ability to restart Path for starting up Timeout for the service startup or shutdown  Service is usually made up of 3 sections:</description>
    </item>
    
    <item>
      <title>Gitlab CLI API reference</title>
      <link>http://abhipandey.com/2016/07/gitlab-cli-api-reference/</link>
      <pubDate>Tue, 05 Jul 2016 23:26:44 +0800</pubDate>
      
      <guid>http://abhipandey.com/2016/07/gitlab-cli-api-reference/</guid>
      <description>Here&amp;rsquo;s a short tutorial on setting up gitlab cli for yourselves. It is extremely user friendly and you can take almost any action that you need. Anything that the UI provides is also available over cli or web services - both of which have examples here.
Let&amp;rsquo;s get started.
gitlab cli Installing the gitlab CLI # http://narkoz.github.io/gitlab/configuration gem install gitlab  Configuration export GITLAB_API_ENDPOINT=&amp;#39;http://gitlab.com/api/v3&amp;#39; export GITLAB_API_PRIVATE_TOKEN=&amp;#39;YOUR_TOKEN_&amp;#39; Available commands $ gitlab +-----------------+ | Help Topics | +-----------------+ | Branches | +-----------------+ | Commits | +-----------------+ | Groups | +-----------------+ | Issues | +-----------------+ | Labels | +-----------------+ | MergeRequests | +-----------------+ | Milestones | +-----------------+ | Namespaces | +-----------------+ | Notes | +-----------------+ | Projects | +-----------------+ | Repositories | +-----------------+ | RepositoryFiles | +-----------------+ | Snippets | +-----------------+ | SystemHooks | +-----------------+ | Users | +-----------------+ Sample CLI commands # Check the list of Projects $ gitlab projects # Based on the response, we know reconwisev2 is ID 487928 # Let&amp;#39;s find out the list of labels in it $ gitlab labels 487928 +---------------------+---------+--------------------+--------------+-------------------+---------------------------+------------+ | Gitlab.</description>
    </item>
    
    <item>
      <title>Protobuf on Docker</title>
      <link>http://abhipandey.com/2016/06/protobuf-on-docker/</link>
      <pubDate>Tue, 28 Jun 2016 23:26:44 +0800</pubDate>
      
      <guid>http://abhipandey.com/2016/06/protobuf-on-docker/</guid>
      <description>Found it really strange that nobody had mentioned on their blog how to compile Protobuf in python with C++ implementation.
I had been having a lot of trouble with the compilation of python protobuf. After struggling with it for a few months on and off I decided to give Docker a try as I realized that my own Fedora OS may be the one having troubles. Thought of starting with Ubuntu Docker as I&amp;rsquo;ve had success with it earlier with such compilation scripts.</description>
    </item>
    
    <item>
      <title>Lambda Basics with Python using Github Webhooks or API Gateway</title>
      <link>http://abhipandey.com/2015/11/lambda-basics-with-python-using-github-webhooks-or-api-gateway/</link>
      <pubDate>Wed, 04 Nov 2015 07:49:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2015/11/lambda-basics-with-python-using-github-webhooks-or-api-gateway/</guid>
      <description>I recently needed to call a command whenever there was a push on my Github repo. Since this was related to AWS tasks, I figured aws lambda is a good candidate. Here I will talk about the steps I took to enable all of this using aws lambda, python. As a side note, I will also elaborate on using API gateway to call upon the lambda itself.
In a nutshell, what I will talk about:</description>
    </item>
    
    <item>
      <title>Setting up custom domain with Github Pages</title>
      <link>http://abhipandey.com/2015/10/setting-up-custom-domain-with-github-pages/</link>
      <pubDate>Sat, 24 Oct 2015 14:59:18 -0400</pubDate>
      
      <guid>http://abhipandey.com/2015/10/setting-up-custom-domain-with-github-pages/</guid>
      <description>Let&amp;rsquo;s take the example of my domain itself abhipandey.com that I want to serve from abhi1010.github.io. We will need to do it in two steps:
 Setup CNAME on github  So that github knows about your domain  Setup A record on AWS Route 53  So that domain can be registered   Change CNAME If we want to tell github about the domain name, it is rather simple: create a CNAME file with the content being the name of the domain itself Do note here that the default redirect of your domain will be the value in your CNAME file.</description>
    </item>
    
    <item>
      <title>Forceful Docker Container cleanup on Elastic Beanstalk</title>
      <link>http://abhipandey.com/2015/10/forceful-docker-container-cleanup-on-elastic-beanstalk/</link>
      <pubDate>Wed, 07 Oct 2015 14:59:18 -0400</pubDate>
      
      <guid>http://abhipandey.com/2015/10/forceful-docker-container-cleanup-on-elastic-beanstalk/</guid>
      <description>Note: If you are not sure of what you are doing here, don&amp;rsquo;t touch it. This is all sensitive stuff and a minor mistake can bring down your production.
Sometimes, because of so many deployments happening and sharing volumes between dockers instances, the space runs out on production server.
I found some ways to fix this but the most brutal way to leave the orphaned directories behind forever is to remove them.</description>
    </item>
    
    <item>
      <title>Automated Git Mirror With GitHub or Gitlab or Bitbucket</title>
      <link>http://abhipandey.com/2015/09/automated-git-mirror-with-github-or-gitlab-or-bitbucket/</link>
      <pubDate>Sun, 27 Sep 2015 13:30:10 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/automated-git-mirror-with-github-or-gitlab-or-bitbucket/</guid>
      <description>Experience with Gitlab CI   Git Mirror from Gitlab to Bitbucket using Gitlab CI
  Had to move from BitBucket to Gitlab; which is really great, btw. However, there was one tiny issue here - Gitlab was not supported by Shippable. As you may know already Shippable is a hosted cloud platform that provides hosted continuous integration. We use it in our current setup to do a full testing and deployment onto AWS Elastic Beanstalk.</description>
    </item>
    
    <item>
      <title>Elastic Beanstalk Deployment Automation</title>
      <link>http://abhipandey.com/2015/09/elastic-beanstalk-deployment-automation/</link>
      <pubDate>Fri, 04 Sep 2015 00:17:10 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/elastic-beanstalk-deployment-automation/</guid>
      <description>We are going to talk about a setup where all you need to do it commit your code and all the rest of the steps from unit tests to deployment can be taken care of by some externally hosted cloud platform that provides continuous integration. In my case, it is going to be Shippable that I am using as a sample but you can use almost anything like TravisCI or codeship, for example.</description>
    </item>
    
    <item>
      <title>Nginx Upload limits on Beanstalk Docker</title>
      <link>http://abhipandey.com/2015/09/nginx-upload-limits-on-beanstalk-docker/</link>
      <pubDate>Fri, 04 Sep 2015 00:14:35 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/nginx-upload-limits-on-beanstalk-docker/</guid>
      <description>If I am not wrong, nginx only allows you to upload up till max 2Mb of data by default. If you are doing a docker deployment on beanstalk you may to remember to change that not once but twice!
As you may know already, beanstalk creates an EC2 instance to manage the docker environment.
Since EC2 needs to manage the docker environment and serve the web interface as well, it does so by having another nginx instance to serve the nginx within docker.</description>
    </item>
    
    <item>
      <title>Updating Django Source with Docker Deployments</title>
      <link>http://abhipandey.com/2015/09/updating-django-source-with-docker-deployments/</link>
      <pubDate>Fri, 04 Sep 2015 00:11:51 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/updating-django-source-with-docker-deployments/</guid>
      <description>While deploying docker multiple times, you may not want to copy over your Django source code every time you do a deployment.
Setting up supervisord Luckily there is an easy way to manage this. Since you are working with Django, there is a good chance that you are also managing the processes (like uwsgi) with supervisord.
Here are some of the steps that you can take with supervisord
 Set up a new process in supervisord Do not allow it to autorestart since it will be a one-shot process Call another script in any format to update the source code  As an example, I use bash to update my source code through git   Here&amp;rsquo;s a sample code:</description>
    </item>
    
    <item>
      <title>Multiple Virtual Environments in Docker</title>
      <link>http://abhipandey.com/2015/09/multiple-virtual-environments-in-docker/</link>
      <pubDate>Thu, 03 Sep 2015 22:33:33 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/multiple-virtual-environments-in-docker/</guid>
      <description>It may seem like a daunting task to have multiple python projects running in their own virtual environments in docker as you want to manage the running of the tasks from a single source - let&amp;rsquo;s say supervisord. However, all that is required here is to know that python automatically picks up the location of the virtual environments if you provide full path to the virtual environment&amp;rsquo;s python.
For example, in my docker environment, I have virtual environment install at the following location:</description>
    </item>
    
    <item>
      <title>Sharing folders on Beanstalk Docker</title>
      <link>http://abhipandey.com/2015/08/sharing-folders-on-beanstalk-docker/</link>
      <pubDate>Fri, 14 Aug 2015 00:19:51 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/08/sharing-folders-on-beanstalk-docker/</guid>
      <description>It is very easy to setup volume sharing in docker. You ideally want the following folders to be shared when a new docker is initialized for you:
 /var/log so that you can keep track of logs nginx specific folders because you will have two instances of nginx running - one on docker and another on EC2. This allows you to share logs  Also read this post for related info  your personal workspace or anything that you&amp;rsquo;d like to share  Here&amp;rsquo;s how you&amp;rsquo;d do it.</description>
    </item>
    
    <item>
      <title>Docker Container cleanup on Elastic Beanstalk</title>
      <link>http://abhipandey.com/2015/08/docker-container-cleanup-on-elastic-beanstalk/</link>
      <pubDate>Fri, 07 Aug 2015 14:59:18 -0400</pubDate>
      
      <guid>http://abhipandey.com/2015/08/docker-container-cleanup-on-elastic-beanstalk/</guid>
      <description>Sometimes you may notice that old containers are not cleaned up from Beanstalk environment. This may be due to your container still running as a ghost on the background. One way to find out about this is to quickly look into your /var/lib/docker/vfs/dir directory whether it has too many folders.
Next, find out what container processes you have going on. [root@ip dir]# docker ps -a
You might see something like this:</description>
    </item>
    
  </channel>
</rss>