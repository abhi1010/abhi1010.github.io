<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on Coders Digest</title>
    <link>http://abhipandey.com/tags/docker/</link>
    <description>Recent content in Docker on Coders Digest</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Jun 2016 23:26:44 +0800</lastBuildDate>
    
	<atom:link href="http://abhipandey.com/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Protobuf on Docker</title>
      <link>http://abhipandey.com/2016/06/protobuf-on-docker/</link>
      <pubDate>Tue, 28 Jun 2016 23:26:44 +0800</pubDate>
      
      <guid>http://abhipandey.com/2016/06/protobuf-on-docker/</guid>
      <description>Found it really strange that nobody had mentioned on their blog how to compile Protobuf in python with C++ implementation.
I had been having a lot of trouble with the compilation of python protobuf. After struggling with it for a few months on and off I decided to give Docker a try as I realized that my own Fedora OS may be the one having troubles. Thought of starting with Ubuntu Docker as I&amp;rsquo;ve had success with it earlier with such compilation scripts.</description>
    </item>
    
    <item>
      <title>Forceful Docker Container cleanup on Elastic Beanstalk</title>
      <link>http://abhipandey.com/2015/10/forceful-docker-container-cleanup-on-elastic-beanstalk/</link>
      <pubDate>Wed, 07 Oct 2015 14:59:18 -0400</pubDate>
      
      <guid>http://abhipandey.com/2015/10/forceful-docker-container-cleanup-on-elastic-beanstalk/</guid>
      <description>Note: If you are not sure of what you are doing here, don&amp;rsquo;t touch it. This is all sensitive stuff and a minor mistake can bring down your production.
Sometimes, because of so many deployments happening and sharing volumes between dockers instances, the space runs out on production server.
I found some ways to fix this but the most brutal way to leave the orphaned directories behind forever is to remove them.</description>
    </item>
    
    <item>
      <title>Elastic Beanstalk Deployment Automation</title>
      <link>http://abhipandey.com/2015/09/elastic-beanstalk-deployment-automation/</link>
      <pubDate>Fri, 04 Sep 2015 00:17:10 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/elastic-beanstalk-deployment-automation/</guid>
      <description>We are going to talk about a setup where all you need to do it commit your code and all the rest of the steps from unit tests to deployment can be taken care of by some externally hosted cloud platform that provides continuous integration. In my case, it is going to be Shippable that I am using as a sample but you can use almost anything like TravisCI or codeship, for example.</description>
    </item>
    
    <item>
      <title>Nginx Upload limits on Beanstalk Docker</title>
      <link>http://abhipandey.com/2015/09/nginx-upload-limits-on-beanstalk-docker/</link>
      <pubDate>Fri, 04 Sep 2015 00:14:35 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/nginx-upload-limits-on-beanstalk-docker/</guid>
      <description>If I am not wrong, nginx only allows you to upload up till max 2Mb of data by default. If you are doing a docker deployment on beanstalk you may to remember to change that not once but twice!
As you may know already, beanstalk creates an EC2 instance to manage the docker environment.
Since EC2 needs to manage the docker environment and serve the web interface as well, it does so by having another nginx instance to serve the nginx within docker.</description>
    </item>
    
    <item>
      <title>Updating Django Source with Docker Deployments</title>
      <link>http://abhipandey.com/2015/09/updating-django-source-with-docker-deployments/</link>
      <pubDate>Fri, 04 Sep 2015 00:11:51 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/updating-django-source-with-docker-deployments/</guid>
      <description>While deploying docker multiple times, you may not want to copy over your Django source code every time you do a deployment.
Setting up supervisord Luckily there is an easy way to manage this. Since you are working with Django, there is a good chance that you are also managing the processes (like uwsgi) with supervisord.
Here are some of the steps that you can take with supervisord
 Set up a new process in supervisord Do not allow it to autorestart since it will be a one-shot process Call another script in any format to update the source code  As an example, I use bash to update my source code through git   Here&amp;rsquo;s a sample code:</description>
    </item>
    
    <item>
      <title>Multiple Virtual Environments in Docker</title>
      <link>http://abhipandey.com/2015/09/multiple-virtual-environments-in-docker/</link>
      <pubDate>Thu, 03 Sep 2015 22:33:33 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/multiple-virtual-environments-in-docker/</guid>
      <description>It may seem like a daunting task to have multiple python projects running in their own virtual environments in docker as you want to manage the running of the tasks from a single source - let&amp;rsquo;s say supervisord. However, all that is required here is to know that python automatically picks up the location of the virtual environments if you provide full path to the virtual environment&amp;rsquo;s python.
For example, in my docker environment, I have virtual environment install at the following location:</description>
    </item>
    
    <item>
      <title>Sharing folders on Beanstalk Docker</title>
      <link>http://abhipandey.com/2015/08/sharing-folders-on-beanstalk-docker/</link>
      <pubDate>Fri, 14 Aug 2015 00:19:51 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/08/sharing-folders-on-beanstalk-docker/</guid>
      <description>It is very easy to setup volume sharing in docker. You ideally want the following folders to be shared when a new docker is initialized for you:
 /var/log so that you can keep track of logs nginx specific folders because you will have two instances of nginx running - one on docker and another on EC2. This allows you to share logs  Also read this post for related info  your personal workspace or anything that you&amp;rsquo;d like to share  Here&amp;rsquo;s how you&amp;rsquo;d do it.</description>
    </item>
    
    <item>
      <title>Docker Container cleanup on Elastic Beanstalk</title>
      <link>http://abhipandey.com/2015/08/docker-container-cleanup-on-elastic-beanstalk/</link>
      <pubDate>Fri, 07 Aug 2015 14:59:18 -0400</pubDate>
      
      <guid>http://abhipandey.com/2015/08/docker-container-cleanup-on-elastic-beanstalk/</guid>
      <description>Sometimes you may notice that old containers are not cleaned up from Beanstalk environment. This may be due to your container still running as a ghost on the background. One way to find out about this is to quickly look into your /var/lib/docker/vfs/dir directory whether it has too many folders.
Next, find out what container processes you have going on. [root@ip dir]# docker ps -a
You might see something like this:</description>
    </item>
    
  </channel>
</rss>