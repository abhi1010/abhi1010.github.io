<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>C&#43;&#43; on Coders Digest</title>
    <link>http://abhipandey.com/tags/c&#43;&#43;/</link>
    <description>Recent content in C&#43;&#43; on Coders Digest</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Jun 2014 15:02:07 +0000</lastBuildDate>
    
	<atom:link href="http://abhipandey.com/tags/c++/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Partition Linked List around a Value X</title>
      <link>http://abhipandey.com/2014/06/partition-linked-list-around-a-value-x/</link>
      <pubDate>Mon, 09 Jun 2014 15:02:07 +0000</pubDate>
      
      <guid>http://abhipandey.com/2014/06/partition-linked-list-around-a-value-x/</guid>
      <description>How do you partition a list around a value x, such that all nodes less than x come before all nodes greater than or equal to x?
Well, there are some solutions possible. The solution, I came up with, is a bit convoluted but let me tell the idea behind it. You want to track the following:
 Two pointers to remember the beginning of the lower and higher series each</description>
    </item>
    
    <item>
      <title>Find the Kth to Last Element of a Singly Linked List</title>
      <link>http://abhipandey.com/2014/06/find-the-kth-to-last-element-of-a-singly-linked-list/</link>
      <pubDate>Sun, 08 Jun 2014 07:49:47 +0000</pubDate>
      
      <guid>http://abhipandey.com/2014/06/find-the-kth-to-last-element-of-a-singly-linked-list/</guid>
      <description>It is possible to a recursive solutions but I will use a simple runner logic. Recursive solutions are usually less optimal.
Note here that, in our logic K=1 would return the last element in the linked list. Similarly, K=2 would return the second last element.
The suggested solution here is to use two pointers:
 One pointer will first travel K items into the list Once that is done, both the pointers start travelling together, one item at a time They keep travelling until the end of linked list is found In that situation, the first pointer is at the end of the list, but the second pointer would have only reached till Kth element - this is what you want  Let&amp;rsquo;s have a look at the code:</description>
    </item>
    
    <item>
      <title>Removing Duplicates from Linked List</title>
      <link>http://abhipandey.com/2014/06/removing-duplicates-from-linked-list/</link>
      <pubDate>Sat, 07 Jun 2014 16:50:12 +0000</pubDate>
      
      <guid>http://abhipandey.com/2014/06/removing-duplicates-from-linked-list/</guid>
      <description>Duplicates can be removed in many ways:
 Create a new Linked List containing only unique items
 Iterate through the Linked List and keep removing items that are being repeated
  The internal structure itself for the algo can either be map or set based. When using map the Node itself can be saved thereby making your life easier if you are creating a new Linked List. However sets can be very useful if we are just iterating through the Linked List and simply deleting items that are being repetetive.</description>
    </item>
    
    <item>
      <title>Deleting a Node from Singly Linked List</title>
      <link>http://abhipandey.com/2014/06/deleting-a-node-from-singly-linked-list/</link>
      <pubDate>Sat, 07 Jun 2014 10:49:17 +0000</pubDate>
      
      <guid>http://abhipandey.com/2014/06/deleting-a-node-from-singly-linked-list/</guid>
      <description>Deleting a Node from Singly Linked List is rather straight forward.
 You have to know the head first of all
 Start by checking the head if that&amp;rsquo;s the one you are looking for
 Keep moving forward and checking - always check for null pointers everywhere
  Before we talk about the code, let&amp;rsquo;s see how Linked List is setup.  Now, below is the code for it&amp;hellip;.</description>
    </item>
    
    <item>
      <title>Usage of typename</title>
      <link>http://abhipandey.com/2014/05/usage-of-typename/</link>
      <pubDate>Mon, 26 May 2014 14:19:15 +0000</pubDate>
      
      <guid>http://abhipandey.com/2014/05/usage-of-typename/</guid>
      <description>What is wrong with the following code?
 The issue is very simple but hard to notice. If you try to compile this, you will get the following errors:
main.cpp:24:5: error: need &amp;#39;typename&amp;#39; before &amp;#39;OuterStruct&amp;lt;T2&amp;gt;::InnerStruct&amp;#39; because &amp;#39;OuterStruct&amp;lt;T2&amp;gt;&amp;#39; is a dependent scope OuterStruct&amp;lt;T2&amp;gt;::InnerStruct mUsingInner; ^ main.cpp: In function &amp;#39;int main(int, char**)&amp;#39;: main.cpp:34:13: error: &amp;#39;struct InnerStruct_Wrapper&amp;lt;int&amp;gt;&amp;#39; has no member named &amp;#39;mUsingInner&amp;#39; wrapper.mUsingInner = innerStrct; The Issue
At least it straight away tells you something is wrong with InnerStruct_Wrapper.</description>
    </item>
    
    <item>
      <title>32 bit vs 64 bit</title>
      <link>http://abhipandey.com/2014/04/32-bit-vs-64-bit/</link>
      <pubDate>Tue, 15 Apr 2014 02:40:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2014/04/32-bit-vs-64-bit/</guid>
      <description>When to use 64-bit? If your application needs more than 2-4gb of data
 If your application intensively uses 64-bit arithmetic * 32-bit x86 compiled applications are restricted to x86 instruction set, even when run on on a 64-bit machine x64 supports 16 registers compared to just 8 in x86. If your code is computation intensive this may help a great deal  When to use 32-bit? After reading so many great things about 32 bit, why would anybody still want to code against 32-bit?</description>
    </item>
    
    <item>
      <title>Tokenize a String using C&#43;&#43;</title>
      <link>http://abhipandey.com/2014/04/tokenize-a-string-using-c-/</link>
      <pubDate>Tue, 08 Apr 2014 07:00:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2014/04/tokenize-a-string-using-c-/</guid>
      <description>Here&amp;rsquo;s a short snippet to split a string into multiple tokens; into a vector. As you will see that, if you run the code, boost version performs better because you can choose a number of delimiters to split your string instead of the vanilla version using the normal C++ code. Of course, you may also write your own code to do something like this but I was looking to do some short snippets.</description>
    </item>
    
    <item>
      <title>Heap Sort vs Merge Sort vs Insertion Sort vs Radix Sort vs Counting Sort vs Quick Sort</title>
      <link>http://abhipandey.com/2014/03/heap-sort-vs-merge-sort-vs-insertion-sort-vs-radix-sort-vs-counting-sort-vs-quick-sort/</link>
      <pubDate>Wed, 19 Mar 2014 05:42:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2014/03/heap-sort-vs-merge-sort-vs-insertion-sort-vs-radix-sort-vs-counting-sort-vs-quick-sort/</guid>
      <description>I had written about sorting algorithms (Tag: Sorting) with details about what to look out for along with their code snippets but I wanted a do a quick comparison of all the algos together to see how do they perform when the same set of input is provided to them. Hence I started working on a simple implementation for each one of them. I have now put together all of them in a single project on GitHub.</description>
    </item>
    
    <item>
      <title>Multiple Inheritance</title>
      <link>http://abhipandey.com/2012/10/multiple-inheritance/</link>
      <pubDate>Tue, 23 Oct 2012 14:21:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2012/10/multiple-inheritance/</guid>
      <description>What is the output to the following code?
 Output
Foo FooToo Bar FootTooBar  Why?
 An instance of FooTooBar needs to be created according to main()
 To create that instance, we first need the base classes too, hence FooToo and Bar classes
 Now notice the keyword virtual everytime inheritance is defined
 This does half the magic by ensuring that the member data instances are shared with any other inclusions of that same base in further derived classes</description>
    </item>
    
    <item>
      <title>Heap Sort</title>
      <link>http://abhipandey.com/2012/10/heap-sort/</link>
      <pubDate>Wed, 17 Oct 2012 14:15:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2012/10/heap-sort/</guid>
      <description>Heap Sort algo has the following properties:
 The top element (root) is always the next in order
 This allows you to remove one element at a time (the root) and ensure that you are pulling out items in a sorted order
 Always takes O(n*log(n)) time - worst case or best case
  Pros and cons to both   Simple implementations require additional space to hold heap of size n</description>
    </item>
    
    <item>
      <title>Merge Sort</title>
      <link>http://abhipandey.com/2012/10/merge-sort/</link>
      <pubDate>Sat, 06 Oct 2012 14:26:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2012/10/merge-sort/</guid>
      <description>Merge Sort
 Complexity is O(n log n) Needs more space to merge - proportional to the size of the array Stable Sort * Preserves the order of equal elements Merge Sort does about 39% lower comparisons, in worst case, compared to Quicksort&amp;rsquo;s average case The algo almost always behaves in the same way; taking relatively the same amount of time, whether sorted or unsorted arrays   Testing Notes  Started testing the algo with two versions.</description>
    </item>
    
    <item>
      <title>Quick Sort</title>
      <link>http://abhipandey.com/2012/09/quick-sort/</link>
      <pubDate>Sat, 22 Sep 2012 14:24:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2012/09/quick-sort/</guid>
      <description>Quick Sort is an efficient divide and conquer algorithm performed in two phases - partition and sorting phase.
Here are few pointers to remember about Quick Sort:
 Partitioning places all the elements less than the pivot in the left part of the array and greater elements in the right part Pivot element stays in its place After partitioning no element moves to the other side, of the pivot * This allows you to sort the elements, to the left or right of the pivot, independent of the other side Complexity is O(n log n) Often fast for small arrays with a few distinct values, repeated many times It is a conquer-and-divide algo; with most of the work happening during partitioning phase If you had to choose the optimum pivot then it should the median of the given array Not a stable sort  Testing Notes  Currently we have only one version of the code.</description>
    </item>
    
    <item>
      <title>Insertion Sort</title>
      <link>http://abhipandey.com/2012/09/insertion-sort/</link>
      <pubDate>Mon, 17 Sep 2012 16:00:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2012/09/insertion-sort/</guid>
      <description>Insertion Sort has the following properties:
 It works by moving elements one at a time Works really well for small data sets Consider going with this when the input data may already be sorted or partially sorted The may not have to move the elements around, thereby saving precious cycles Stable sort Keeps the original order of elements with equal values  Testing Notes  Had a very interesting time testing my code.</description>
    </item>
    
    <item>
      <title>Radix Sort</title>
      <link>http://abhipandey.com/2012/09/radix-sort/</link>
      <pubDate>Thu, 13 Sep 2012 10:37:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2012/09/radix-sort/</guid>
      <description>It is a non-comparative integer sorting algorithm. It sorts data by grouping keys by the individual digits which share the same significant position and value. Think Tens, Hundreds, Thousands etc. Some pointers about Radix Sort:
 Even though it is an integer sorting algorithm, it is not restricted just to integers. Integers can also represent strings of characters Two types of radix sort are:  LSD (Least Significant Digit): Short keys come before long keys MSD (Most Significant Digit) Sorting: Lexicographic Order.</description>
    </item>
    
    <item>
      <title>Counting Sort</title>
      <link>http://abhipandey.com/2012/09/counting-sort/</link>
      <pubDate>Tue, 11 Sep 2012 10:03:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2012/09/counting-sort/</guid>
      <description>Counting Sort is an integer sorting algorithm. It is not very famous when somebody talks about sorting algorithms but it is great when sorting integers. In fact, many a times it may even beat other Sorting Algorithms. The highlight of Counting Sort is that it creates a bucket array (to keep track of frequency of numbers) whose size is the maximum element in the provided array.
We are looking to compare most of the sorting algorithms to find out which one performs better under different circumstances.</description>
    </item>
    
  </channel>
</rss>