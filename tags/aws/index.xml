<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws on Coders Digest</title>
    <link>http://abhipandey.com/tags/aws/</link>
    <description>Recent content in Aws on Coders Digest</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Nov 2015 07:49:00 +0000</lastBuildDate>
    
	<atom:link href="http://abhipandey.com/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Lambda Basics with Python using Github Webhooks or API Gateway</title>
      <link>http://abhipandey.com/2015/11/lambda-basics-with-python-using-github-webhooks-or-api-gateway/</link>
      <pubDate>Wed, 04 Nov 2015 07:49:00 +0000</pubDate>
      
      <guid>http://abhipandey.com/2015/11/lambda-basics-with-python-using-github-webhooks-or-api-gateway/</guid>
      <description>I recently needed to call a command whenever there was a push on my Github repo. Since this was related to AWS tasks, I figured aws lambda is a good candidate. Here I will talk about the steps I took to enable all of this using aws lambda, python. As a side note, I will also elaborate on using API gateway to call upon the lambda itself.
In a nutshell, what I will talk about:</description>
    </item>
    
    <item>
      <title>Setting up custom domain with Github Pages</title>
      <link>http://abhipandey.com/2015/10/setting-up-custom-domain-with-github-pages/</link>
      <pubDate>Sat, 24 Oct 2015 14:59:18 -0400</pubDate>
      
      <guid>http://abhipandey.com/2015/10/setting-up-custom-domain-with-github-pages/</guid>
      <description>Let&amp;rsquo;s take the example of my domain itself abhipandey.com that I want to serve from abhi1010.github.io. We will need to do it in two steps:
 Setup CNAME on github  So that github knows about your domain  Setup A record on AWS Route 53  So that domain can be registered   Change CNAME If we want to tell github about the domain name, it is rather simple: create a CNAME file with the content being the name of the domain itself Do note here that the default redirect of your domain will be the value in your CNAME file.</description>
    </item>
    
    <item>
      <title>Forceful Docker Container cleanup on Elastic Beanstalk</title>
      <link>http://abhipandey.com/2015/10/forceful-docker-container-cleanup-on-elastic-beanstalk/</link>
      <pubDate>Wed, 07 Oct 2015 14:59:18 -0400</pubDate>
      
      <guid>http://abhipandey.com/2015/10/forceful-docker-container-cleanup-on-elastic-beanstalk/</guid>
      <description>Note: If you are not sure of what you are doing here, don&amp;rsquo;t touch it. This is all sensitive stuff and a minor mistake can bring down your production.
Sometimes, because of so many deployments happening and sharing volumes between dockers instances, the space runs out on production server.
I found some ways to fix this but the most brutal way to leave the orphaned directories behind forever is to remove them.</description>
    </item>
    
    <item>
      <title>Automated Git Mirror With GitHub or Gitlab or Bitbucket</title>
      <link>http://abhipandey.com/2015/09/automated-git-mirror-with-github-or-gitlab-or-bitbucket/</link>
      <pubDate>Sun, 27 Sep 2015 13:30:10 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/automated-git-mirror-with-github-or-gitlab-or-bitbucket/</guid>
      <description>Experience with Gitlab CI   Git Mirror from Gitlab to Bitbucket using Gitlab CI
  Had to move from BitBucket to Gitlab; which is really great, btw. However, there was one tiny issue here - Gitlab was not supported by Shippable. As you may know already Shippable is a hosted cloud platform that provides hosted continuous integration. We use it in our current setup to do a full testing and deployment onto AWS Elastic Beanstalk.</description>
    </item>
    
    <item>
      <title>Elastic Beanstalk Deployment Automation</title>
      <link>http://abhipandey.com/2015/09/elastic-beanstalk-deployment-automation/</link>
      <pubDate>Fri, 04 Sep 2015 00:17:10 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/09/elastic-beanstalk-deployment-automation/</guid>
      <description>We are going to talk about a setup where all you need to do it commit your code and all the rest of the steps from unit tests to deployment can be taken care of by some externally hosted cloud platform that provides continuous integration. In my case, it is going to be Shippable that I am using as a sample but you can use almost anything like TravisCI or codeship, for example.</description>
    </item>
    
    <item>
      <title>Sharing folders on Beanstalk Docker</title>
      <link>http://abhipandey.com/2015/08/sharing-folders-on-beanstalk-docker/</link>
      <pubDate>Fri, 14 Aug 2015 00:19:51 +0800</pubDate>
      
      <guid>http://abhipandey.com/2015/08/sharing-folders-on-beanstalk-docker/</guid>
      <description>It is very easy to setup volume sharing in docker. You ideally want the following folders to be shared when a new docker is initialized for you:
 /var/log so that you can keep track of logs nginx specific folders because you will have two instances of nginx running - one on docker and another on EC2. This allows you to share logs  Also read this post for related info  your personal workspace or anything that you&amp;rsquo;d like to share  Here&amp;rsquo;s how you&amp;rsquo;d do it.</description>
    </item>
    
    <item>
      <title>Docker Container cleanup on Elastic Beanstalk</title>
      <link>http://abhipandey.com/2015/08/docker-container-cleanup-on-elastic-beanstalk/</link>
      <pubDate>Fri, 07 Aug 2015 14:59:18 -0400</pubDate>
      
      <guid>http://abhipandey.com/2015/08/docker-container-cleanup-on-elastic-beanstalk/</guid>
      <description>Sometimes you may notice that old containers are not cleaned up from Beanstalk environment. This may be due to your container still running as a ghost on the background. One way to find out about this is to quickly look into your /var/lib/docker/vfs/dir directory whether it has too many folders.
Next, find out what container processes you have going on. [root@ip dir]# docker ps -a
You might see something like this:</description>
    </item>
    
  </channel>
</rss>